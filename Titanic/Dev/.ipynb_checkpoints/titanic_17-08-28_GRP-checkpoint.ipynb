{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os, sys\n",
    "\n",
    "# pandas\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#keras\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers import Input, concatenate, Flatten, BatchNormalization\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import Adam\n",
    "sys.path.append('../../lotufo')\n",
    "from my_keras_utilities import (get_available_gpus, load_model_and_history, save_model_and_history, TrainingPlotter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic_train = pd.read_csv('../Data/train.csv')\n",
    "titanic_test = pd.read_csv('../Data/test.csv')\n",
    "\n",
    "# print(titanic_train.info())\n",
    "# print('-'*100)\n",
    "# print(titanic_test.info())\n",
    "# # titanic_train.head(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove not interesting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic_train = titanic_train.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "titanic_test = titanic_test.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "# print(titanic_train.info())\n",
    "# print('-'*100)\n",
    "# print(titanic_test.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove rows with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass   Sex   Age  SibSp  Parch  Fare Embarked\n",
       "0         0       3  male  22.0      1      0  7.25        S"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_train = titanic_train[titanic_train.Age.notnull()]\n",
    "titanic_test = titanic_test[titanic_test.Age.notnull()]\n",
    "\n",
    "titanic_train = titanic_train[titanic_train.Embarked.notnull()]\n",
    "titanic_test = titanic_test[titanic_test.Embarked.notnull()]\n",
    "\n",
    "# print(titanic_train.info())\n",
    "# print('-'*100)\n",
    "# print(titanic_test.info())\n",
    "titanic_train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train\n",
    "Pclass_classes_train, Pclass_norm_train = np.unique(titanic_train.Pclass.as_matrix(), return_inverse=True)\n",
    "Sex_classes_train, Sex_norm_train = np.unique(titanic_train.Sex.as_matrix(), return_inverse=True)\n",
    "# SibSp_classes_train, SibSp_norm_train = np.unique(titanic_train.SibSp.as_matrix(), return_inverse=True)\n",
    "# Parch_classes_train, Parch_norm_train = np.unique(titanic_train.Parch.as_matrix(), return_inverse=True)\n",
    "Embarked_classes_train, Embarked_norm_train = np.unique(titanic_train.Embarked.as_matrix(), return_inverse=True)\n",
    "\n",
    "#test\n",
    "Pclass_classes_test, Pclass_norm_test = np.unique(titanic_test.Pclass.as_matrix(), return_inverse=True)\n",
    "Sex_classes_test, Sex_norm_test = np.unique(titanic_test.Sex.as_matrix(), return_inverse=True)\n",
    "# SibSp_classes_test, SibSp_norm_test = np.unique(titanic_test.SibSp.as_matrix(), return_inverse=True)\n",
    "# Parch_classes_test, Parch_norm_test = np.unique(titanic_test.Parch.as_matrix(), return_inverse=True)\n",
    "Embarked_classes_test, Embarked_norm_test = np.unique(titanic_test.Embarked.as_matrix(), return_inverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize non categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train\n",
    "Pclass_classes_train, Pclass_norm_train = np.unique(titanic_train.Pclass.as_matrix(), return_inverse=True)\n",
    "\n",
    "\n",
    "#test\n",
    "Pclass_classes_test, Pclass_norm_test = np.unique(titanic_test.Pclass.as_matrix(), return_inverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "Pclass_in (InputLayer)           (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "Embarked (InputLayer)            (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "Pclass_embedding (Embedding)     (None, 1, 2)          6           Pclass_in[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "Sex_in (InputLayer)              (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "Age_in (InputLayer)              (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "SibSp_in (InputLayer)            (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "Parch_in (InputLayer)            (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "Fare_in (InputLayer)             (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "Embarked_embedding (Embedding)   (None, 1, 2)          6           Embarked[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "Pclass_flatten (Flatten)         (None, 2)             0           Pclass_embedding[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 1)             2           Sex_in[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 1)             2           Age_in[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_11 (Dense)                 (None, 1)             2           SibSp_in[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_12 (Dense)                 (None, 1)             2           Parch_in[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_13 (Dense)                 (None, 1)             2           Fare_in[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "Embarked_flatten (Flatten)       (None, 2)             0           Embarked_embedding[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 9)             0           Pclass_flatten[0][0]             \n",
      "                                                                   dense_9[0][0]                    \n",
      "                                                                   dense_10[0][0]                   \n",
      "                                                                   dense_11[0][0]                   \n",
      "                                                                   dense_12[0][0]                   \n",
      "                                                                   dense_13[0][0]                   \n",
      "                                                                   Embarked_flatten[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dense_14 (Dense)                 (None, 1000)          10000       concatenate_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_15 (Dense)                 (None, 500)           500500      dense_14[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_16 (Dense)                 (None, 1)             501         dense_15[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 511,023\n",
      "Trainable params: 511,023\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Survived Pclass Sex Age SibSp Parch Fare Embarked\n",
    "def build_keras_model():\n",
    "    Pclass_in = Input(shape=(1,), dtype='int64', name='Pclass_in')\n",
    "    x = Embedding(Pclass_classes_train.size, 2, input_length=1, name='Pclass_embedding')(Pclass_in)\n",
    "    Pclass_emb = Flatten(name='Pclass_flatten')(x)\n",
    "    \n",
    "    Sex_in = Input(shape=(1,), name='Sex_in')\n",
    "    Sex_out = Dense(1, input_dim=1)(Sex_in)\n",
    "    \n",
    "    Age_in = Input(shape=(1,), name='Age_in')\n",
    "    Age_out = Dense(1, input_dim=1)(Age_in)\n",
    "    \n",
    "    SibSp_in = Input(shape=(1,), name='SibSp_in')\n",
    "    SibSp_out = Dense(1, input_dim=1)(SibSp_in)\n",
    "    \n",
    "    Parch_in = Input(shape=(1,), name='Parch_in')\n",
    "    Parch_out = Dense(1, input_dim=1)(Parch_in)\n",
    "    \n",
    "    Fare_in = Input(shape=(1,), name='Fare_in')\n",
    "    Fare_out = Dense(1, input_dim=1)(Fare_in)\n",
    "    \n",
    "    Embarked_in = Input(shape=(1,), dtype='int64', name='Embarked')\n",
    "    x = Embedding(3, 2, input_length=1, name='Embarked_embedding')(Embarked_in)\n",
    "    Embarked_emb = Flatten(name='Embarked_flatten')(x)\n",
    "    \n",
    "    \n",
    "    xin = concatenate([Pclass_emb, Sex_out, Age_out, SibSp_out, Parch_out, Fare_out, Embarked_emb])\n",
    "    x = Dense(1000, kernel_initializer='uniform', activation='relu')(xin)\n",
    "    x = Dense(500, kernel_initializer='uniform', activation='relu')(x)\n",
    "    x_out = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    return Model([Pclass_in, Sex_in, Age_in, SibSp_in, Parch_in, Fare_in, Embarked_in], x_out)\n",
    "\n",
    "model_ti = build_keras_model()\n",
    "model_ti.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_records = len(titanic_train['Survived'].as_matrix())\n",
    "train_ratio = 0.7\n",
    "train_size = int(train_ratio * num_records)\n",
    "\n",
    "\n",
    "X_train_p = [Pclass_norm_train[:train_size], Sex_norm_train[:train_size], titanic_train['Age'].as_matrix()[:train_size],\n",
    "             titanic_train['SibSp'].as_matrix()[:train_size], titanic_train['Parch'].as_matrix()[:train_size],\n",
    "             titanic_train['Fare'].as_matrix()[:train_size], Embarked_norm_train[:train_size]]\n",
    "y_train = titanic_train['Survived'].as_matrix()[:train_size]\n",
    "\n",
    "X_val_p = [Pclass_norm_train[train_size:], Sex_norm_train[train_size:], titanic_train['Age'].as_matrix()[train_size:],\n",
    "             titanic_train['SibSp'].as_matrix()[train_size:], titanic_train['Parch'].as_matrix()[train_size:],\n",
    "             titanic_train['Fare'].as_matrix()[train_size:], Embarked_norm_train[train_size:]]\n",
    "y_val = titanic_train['Survived'].as_matrix()[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "498/498 [==============================] - 0s - loss: 0.1476     \n",
      "Epoch 2/50\n",
      "498/498 [==============================] - 0s - loss: 0.1314     \n",
      "Epoch 3/50\n",
      "498/498 [==============================] - 0s - loss: 0.1342     \n",
      "Epoch 4/50\n",
      "498/498 [==============================] - 0s - loss: 0.1356     \n",
      "Epoch 5/50\n",
      "498/498 [==============================] - 0s - loss: 0.1336     \n",
      "Epoch 6/50\n",
      "498/498 [==============================] - 0s - loss: 0.1293     \n",
      "Epoch 7/50\n",
      "498/498 [==============================] - 0s - loss: 0.1293     \n",
      "Epoch 8/50\n",
      "498/498 [==============================] - 0s - loss: 0.1346     \n",
      "Epoch 9/50\n",
      "498/498 [==============================] - 0s - loss: 0.1303     \n",
      "Epoch 10/50\n",
      "498/498 [==============================] - 0s - loss: 0.1248     \n",
      "Epoch 11/50\n",
      "498/498 [==============================] - 0s - loss: 0.1260     \n",
      "Epoch 12/50\n",
      "498/498 [==============================] - 0s - loss: 0.1250     \n",
      "Epoch 13/50\n",
      "498/498 [==============================] - 0s - loss: 0.1305     \n",
      "Epoch 14/50\n",
      "498/498 [==============================] - 0s - loss: 0.1247     \n",
      "Epoch 15/50\n",
      "498/498 [==============================] - 0s - loss: 0.1345     \n",
      "Epoch 16/50\n",
      "498/498 [==============================] - 0s - loss: 0.1294     \n",
      "Epoch 17/50\n",
      "498/498 [==============================] - 0s - loss: 0.1314     \n",
      "Epoch 18/50\n",
      "498/498 [==============================] - 0s - loss: 0.1262     \n",
      "Epoch 19/50\n",
      "498/498 [==============================] - 0s - loss: 0.1236     \n",
      "Epoch 20/50\n",
      "498/498 [==============================] - 0s - loss: 0.1260     \n",
      "Epoch 21/50\n",
      "498/498 [==============================] - 0s - loss: 0.1285     \n",
      "Epoch 22/50\n",
      "498/498 [==============================] - 0s - loss: 0.1328     \n",
      "Epoch 23/50\n",
      "498/498 [==============================] - 0s - loss: 0.1278     \n",
      "Epoch 24/50\n",
      "498/498 [==============================] - 0s - loss: 0.1208     \n",
      "Epoch 25/50\n",
      "498/498 [==============================] - 0s - loss: 0.1344     \n",
      "Epoch 26/50\n",
      "498/498 [==============================] - 0s - loss: 0.1282     \n",
      "Epoch 27/50\n",
      "498/498 [==============================] - 0s - loss: 0.1220     \n",
      "Epoch 28/50\n",
      "498/498 [==============================] - 0s - loss: 0.1323     \n",
      "Epoch 29/50\n",
      "498/498 [==============================] - 0s - loss: 0.1269     \n",
      "Epoch 30/50\n",
      "498/498 [==============================] - 0s - loss: 0.1348     \n",
      "Epoch 31/50\n",
      "498/498 [==============================] - 0s - loss: 0.1217     \n",
      "Epoch 32/50\n",
      "498/498 [==============================] - 0s - loss: 0.1224     \n",
      "Epoch 33/50\n",
      "498/498 [==============================] - 0s - loss: 0.1246     \n",
      "Epoch 34/50\n",
      "498/498 [==============================] - 0s - loss: 0.1200     \n",
      "Epoch 35/50\n",
      "498/498 [==============================] - 0s - loss: 0.1323     \n",
      "Epoch 36/50\n",
      "498/498 [==============================] - 0s - loss: 0.1261     \n",
      "Epoch 37/50\n",
      "498/498 [==============================] - 0s - loss: 0.1213     \n",
      "Epoch 38/50\n",
      "498/498 [==============================] - 0s - loss: 0.1231     \n",
      "Epoch 39/50\n",
      "498/498 [==============================] - 0s - loss: 0.1256     \n",
      "Epoch 40/50\n",
      "498/498 [==============================] - 0s - loss: 0.1258     \n",
      "Epoch 41/50\n",
      "498/498 [==============================] - 0s - loss: 0.1249     \n",
      "Epoch 42/50\n",
      "498/498 [==============================] - 0s - loss: 0.1173     \n",
      "Epoch 43/50\n",
      "498/498 [==============================] - 0s - loss: 0.1268     \n",
      "Epoch 44/50\n",
      "498/498 [==============================] - 0s - loss: 0.1187     \n",
      "Epoch 45/50\n",
      "498/498 [==============================] - 0s - loss: 0.1242     \n",
      "Epoch 46/50\n",
      "498/498 [==============================] - 0s - loss: 0.1195     \n",
      "Epoch 47/50\n",
      "498/498 [==============================] - 0s - loss: 0.1264     \n",
      "Epoch 48/50\n",
      "498/498 [==============================] - 0s - loss: 0.1239     \n",
      "Epoch 49/50\n",
      "498/498 [==============================] - 0s - loss: 0.1233     \n",
      "Epoch 50/50\n",
      "498/498 [==============================] - 0s - loss: 0.1237     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25b1dabaa90>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For a mean squared error regression problem\n",
    "model_ti.compile(optimizer='rmsprop', loss='mse')\n",
    "\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "model_ti.fit(X_train_p, y_train, epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss: 0.10290114888\n",
      "Bias:\n",
      " [[-0.42652225  0.42300346]\n",
      " [-0.14842899  0.19342794]\n",
      " [ 0.03573124 -0.0676112 ]]\n",
      "W:\n",
      " [[-0.2773459  -0.18338183]\n",
      " [-0.22380771 -0.31480265]\n",
      " [ 0.23386265  0.26994267]]\n"
     ]
    }
   ],
   "source": [
    "loss = model_ti.evaluate(X_val_p, y_val, verbose=0)\n",
    "print('Final loss:',loss)\n",
    "\n",
    "W = model_ti.get_weights()\n",
    "print('Bias:\\n', W[1])\n",
    "print('W:\\n', W[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_hat = model_ti.predict(X_val_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83644859813084116"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_hat\n",
    "# y_val\n",
    "\n",
    "accuracy = sum((Y_hat.reshape(len(y_val))>0.5) == y_val)/(float(len(y_val)))\n",
    "accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras.utils import plot_model\n",
    "# plot_model(model_rs, to_file='model_rs.png')\n",
    "# print pydot.find_graphviz()\n",
    "\n",
    "# from IPython.display import SVG\n",
    "# from keras.utils.vis_utils import model_to_dot\n",
    "# SVG(model_to_dot(model_rs).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TrainingPlotter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-16fef1dd4ad5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mMyCb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTrainingPlotter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TrainingPlotter' is not defined"
     ]
    }
   ],
   "source": [
    "class MyCb(TrainingPlotter):\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        super().on_epoch_end(epoch, logs)\n",
    "        \n",
    "def train_network(model, X_train, y_train, Xval, yval, \n",
    "                  model_name = None,\n",
    "                  loss=\"categorical_crossentropy\",\n",
    "                  opt='rmsprop', batch_size=60, nepochs=100, patience=10, nr_seed=20170522, \n",
    "                  shuffle=True,\n",
    "                  reset=False, ploss=1.0):\n",
    "\n",
    "    do_plot = (ploss > 0.0)\n",
    "    \n",
    "    model_fn = model_name + '.model'\n",
    "    if reset and os.path.isfile(model_fn):\n",
    "        os.unlink(model_name + '.model')\n",
    "        \n",
    "    if not os.path.isfile(model_fn):\n",
    "        # initialize the optimizer and model\n",
    "        print(\"[INFO] compiling model...\")\n",
    "        model.compile(loss=loss, optimizer=opt, metrics=[\"accuracy\"])    \n",
    "\n",
    "        # History, checkpoint, earlystop, plot losses:\n",
    "        cb = MyCb(n=1, filepath=model_name, patience=patience, plot_losses=do_plot)\n",
    "        \n",
    "    else:\n",
    "        print(\"[INFO] loading model...\")\n",
    "        model, cb = load_model_and_history(model_name)\n",
    "        cb.patience = patience\n",
    "\n",
    "    past_epochs = cb.get_nepochs()\n",
    "    tr_epochs = nepochs - past_epochs\n",
    "    \n",
    "    if do_plot:\n",
    "        import matplotlib.pyplot as plot\n",
    "        vv = 0\n",
    "        fig = plot.figure(figsize=(15,6))\n",
    "        plot.ylim(0.0, ploss)\n",
    "        plot.xlim(0, nepochs)\n",
    "        plot.grid(True)\n",
    "    else:\n",
    "        vv = 2\n",
    "\n",
    "    print(\"[INFO] training for {} epochs...\".format(tr_epochs))\n",
    "    try:\n",
    "        h = model.fit(X_train, y_train, batch_size=60, epochs=tr_epochs, verbose=0, \n",
    "                      validation_data=(Xval, yval),\n",
    "                      shuffle=shuffle,\n",
    "                      callbacks=[cb])\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "\n",
    "    return model, cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_records = len(titanic_train['Survived'].as_matrix())\n",
    "train_ratio = 0.9\n",
    "train_size = int(train_ratio * num_records)\n",
    "\n",
    "\n",
    "X_train_p = [Pclass_norm_train[:train_size], Sex_norm_train[:train_size], titanic_train['Age'].as_matrix()[:train_size],\n",
    "             titanic_train['SibSp'].as_matrix()[:train_size], titanic_train['Parch'].as_matrix()[:train_size],\n",
    "             titanic_train['Fare'].as_matrix()[:train_size], Embarked_norm_train[:train_size]]\n",
    "y_train = titanic_train['Survived'].as_matrix()[:train_size]\n",
    "\n",
    "X_val_p = [Pclass_norm_train[train_size:], Sex_norm_train[train_size:], titanic_train['Age'].as_matrix()[train_size:],\n",
    "             titanic_train['SibSp'].as_matrix()[train_size:], titanic_train['Parch'].as_matrix()[train_size:],\n",
    "             titanic_train['Fare'].as_matrix()[train_size:], Embarked_norm_train[train_size:]]\n",
    "y_val = titanic_train['Survived'].as_matrix()[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'MyCb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-5cc53702968e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m }\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mtrain_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_rs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-41-0d5d9783f0ae>\u001b[0m in \u001b[0;36mtrain_network\u001b[1;34m(model, X_train, y_train, Xval, yval, model_name, loss, opt, batch_size, nepochs, patience, nr_seed, shuffle, reset, ploss)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m# History, checkpoint, earlystop, plot losses:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMyCb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpatience\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_losses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdo_plot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MyCb' is not defined"
     ]
    }
   ],
   "source": [
    "model_name = '../../models/rossmann'\n",
    "fit_params = {\n",
    "    'model_name': model_name,\n",
    "    'loss': 'mean_absolute_error',\n",
    "    'opt':        Adam(), \n",
    "    'batch_size': 128, \n",
    "    'nepochs':    5,\n",
    "    'patience':   5,\n",
    "    'ploss':      0.015,\n",
    "    'shuffle':    False,\n",
    "    'reset':      True,\n",
    "}\n",
    "\n",
    "train_network(model_rs, X_train_p, y_train, X_val_p, y_val, **fit_params);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# titanic_train.Sex.as_matrix()\n",
    "# titanic_train.Sex = 1\n",
    "import graphviz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes, i_norm = np.unique(titanic_train.Sex.as_matrix(), return_inverse=True)\n",
    "# titanic_train.Sex_norm = np.unique(titanic_train.Sex.as_matrix(), return_inverse=True)\n",
    "titanic_train.Sex_norm = i_norm\n",
    "i_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#normalize\n",
    "titanic_train = titanic_train.as_matrix()\n",
    "X_norm = np.empty_like(titanic_train)\n",
    "ndex_norm_coll = [1, 2, -1]\n",
    "for i in ndex_norm_coll: # para cada coluna (atributo)\n",
    "    classes, i_norm = np.unique(titanic_train[:,i], return_inverse=True)\n",
    "    titanic_train[:,i] = i_norm\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# titanic_train.values[:,0]\n",
    "titanic_train.as_matrix([5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class trainset(object):\n",
    "    PassengerId = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NomeDaClasse.seq"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
